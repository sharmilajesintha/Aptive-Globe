{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read a text file in python, find the shortest word, longest word and the average length of the words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def word(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        num_words = 0\n",
    "        num_chars = 0\n",
    "        all_words = []\n",
    "\n",
    "        for line in file:\n",
    "            clean = re.sub(r'[^\\w\\s]', '', line)\n",
    "            words = clean.split()\n",
    "            all_words.extend(words)\n",
    "            \n",
    "        num_words = len(all_words)\n",
    "        max_len = len(max(all_words,key=len)) \n",
    "        min_len = len(min(all_words,key=len))\n",
    "        \n",
    "        for w in all_words:\n",
    "            num_chars += len(w)\n",
    "            if len(w) == max_len:\n",
    "                Longest_Word = w\n",
    "            if len(w) == min_len:\n",
    "                Shortest_Word = w\n",
    "\n",
    "        avg = round(num_chars / num_words)\n",
    "    print(\"Words in the file: {}\".format(all_words))\n",
    "    print(\"Total number of words: {}\".format(num_words))\n",
    "    print(\"Total word length: {}\".format(num_chars))\n",
    "    print(\"Average word length: {}\".format(avg))\n",
    "    print(\"Longest_Word: {}\".format(Longest_Word))\n",
    "    print(\"Shortest_Word: {}\".format(Shortest_Word))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in the file: ['This', 'is', 'a', 'sample', 'file', 'To', 'find', 'the', 'long', 'short', 'words', 'and', 'average', 'length', 'of', 'the', 'words']\n",
      "Total number of words: 17\n",
      "Total word length: 66\n",
      "Average word length: 4\n",
      "Longest_Word: average\n",
      "Shortest_Word: a\n"
     ]
    }
   ],
   "source": [
    "word(\"Samplefile.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a program to sort the list of tuples by values. Do not use library in-built function. Run your program on x = [(1,3),(2,10),(30,1),(10,2)], and print the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort_Tuple(tup):  \n",
    "      \n",
    "    length = len(tup)  \n",
    "    for i in range(length):  \n",
    "          \n",
    "        for j in range(length-i-1):  \n",
    "            if (tup[j][1] > tup[j + 1][1]):  \n",
    "                temp = tup[j]  \n",
    "                tup[j]= tup[j + 1]  \n",
    "                tup[j + 1]= temp  \n",
    "                \n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(30, 1), (10, 2), (1, 3), (2, 10)]\n"
     ]
    }
   ],
   "source": [
    "x = [(1,3),(2,10),(30,1),(10,2)]\n",
    "        \n",
    "print(Sort_Tuple(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort_Tuple2(tup):  \n",
    "      \n",
    "    length = len(tup)  \n",
    "    for i in range(length):  \n",
    "          \n",
    "        for j in range(length-i-1):  \n",
    "            if (tup[j][0] > tup[j + 1][0]):  \n",
    "                temp = tup[j]  \n",
    "                tup[j]= tup[j + 1]  \n",
    "                tup[j + 1]= temp  \n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 3), (2, 10), (10, 2), (30, 1)]\n"
     ]
    }
   ],
   "source": [
    "x = [(1,3),(2,10),(30,1),(10,2)]\n",
    "        \n",
    "print(Sort_Tuple2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load the Iris dataset to MariaDB database. Using a python library for MariaDB, find out maximum, and minimum values of Sepal Length for Virginica, setosa, versicolor.\n",
    "Sorry i have not worked in Database connected environment from python. So i dont have the neccessary software installed.\n",
    "But i have experience working in SQL DB in my previos work, i can assure that i will learn quick in real work environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. If x1,y1, and x2,y2 are coordinates of opposite verticies of the square, find out the center of diagonals of the square. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def square(x1=1,x2=3,y1=2,y2=4):\n",
    "    #Length of Side\n",
    "    Side_Len = sqrt(((y2 - y1) * (y2 - y1)) + ((x2 - x1) * (x2 - x1)))\n",
    "\n",
    "    #Length of Diagonal\n",
    "    diag_Len = sqrt(2)*(Side_Len)\n",
    "    #Center of diagonals\n",
    "    diag_center = diag_Len/2\n",
    "\n",
    "    print(round(Side_Len,2), round(diag_Len,2), round(diag_center,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.83 4.0 2.0\n"
     ]
    }
   ],
   "source": [
    "square(3,5,6,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write a simple python script that will print all the file names in given directory every 10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aptive Globe.ipynb\n",
      "Aptive Globe_Assignment.ipynb\n",
      "bank-additional-full.csv\n",
      "Classification model.ipynb\n",
      "day1.ipynb\n",
      "Iris.txt\n",
      "OTM.ipynb\n",
      "Samplefile.txt\n",
      "Aptive Globe.ipynb\n",
      "Aptive Globe_Assignment.ipynb\n",
      "bank-additional-full.csv\n",
      "Classification model.ipynb\n",
      "day1.ipynb\n",
      "Iris.txt\n",
      "OTM.ipynb\n",
      "Samplefile.txt\n",
      "Aptive Globe.ipynb\n",
      "Aptive Globe_Assignment.ipynb\n",
      "bank-additional-full.csv\n",
      "Classification model.ipynb\n",
      "day1.ipynb\n",
      "Iris.txt\n",
      "OTM.ipynb\n",
      "Samplefile.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import threading\n",
    "\n",
    "def printfiles():\n",
    "    threading.Timer(10.0, printfiles).start()\n",
    "    basepath = 'C:/Python learning'\n",
    "    with os.scandir(basepath) as entries:\n",
    "        for entry in entries:\n",
    "            if entry.is_file():\n",
    "                print(entry.name)\n",
    "\n",
    "printfiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Build three prediction model on the banking data - https://archive.ics.uci.edu/ml/datasets/Bank%2BMarketing\n",
    "   Compare the F1 score for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn as sk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"bank-additional-full.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values in the data. And the datatypes of the variables are read correctly so there may not be any invalid values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To label encode the categorical varaibles in the target column to nominal variable.\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelencoding\n",
    "le = LabelEncoder()\n",
    "var_mod = data.select_dtypes(include='object').columns\n",
    "for i in var_mod:\n",
    "    data[i] = le.fit_transform(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  housing  loan  contact  month  \\\n",
       "0   56    3        1          0        0        0     0        1      6   \n",
       "1   57    7        1          3        1        0     0        1      6   \n",
       "2   37    7        1          3        0        2     0        1      6   \n",
       "3   40    0        1          1        0        0     0        1      6   \n",
       "4   56    7        1          3        0        0     2        1      6   \n",
       "\n",
       "   day_of_week  ...  campaign  pdays  previous  poutcome  emp.var.rate  \\\n",
       "0            1  ...         1    999         0         1           1.1   \n",
       "1            1  ...         1    999         0         1           1.1   \n",
       "2            1  ...         1    999         0         1           1.1   \n",
       "3            1  ...         1    999         0         1           1.1   \n",
       "4            1  ...         1    999         0         1           1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
       "0          93.994          -36.4      4.857       5191.0  0  \n",
       "1          93.994          -36.4      4.857       5191.0  0  \n",
       "2          93.994          -36.4      4.857       5191.0  0  \n",
       "3          93.994          -36.4      4.857       5191.0  0  \n",
       "4          93.994          -36.4      4.857       5191.0  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate Features and Target\n",
    "X= data.drop(columns = ['y'], axis=1)\n",
    "y= data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train  (32950, 20)\n",
      "X_test  (8238, 20)\n",
      "y_train  (32950,)\n",
      "y_test  (8238,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=22)\n",
    "print(\"X_train \",X_train.shape)\n",
    "print(\"X_test \",X_test.shape)\n",
    "print(\"y_train \",y_train.shape)\n",
    "print(\"y_test \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Standardization - Input variable\n",
    "###################\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "Scaling = MinMaxScaler().fit(X_train)\n",
    "x_train_std = Scaling.transform(X_train) # This step standardizes the train input data\n",
    "x_test_std = Scaling.transform(X_test) # This step standardizes the test input data\n",
    "\n",
    "X_train = pd.DataFrame(x_train_std, columns = X_train.columns)\n",
    "X_test = pd.DataFrame(x_test_std, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.00000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.284447</td>\n",
       "      <td>0.339288</td>\n",
       "      <td>0.391118</td>\n",
       "      <td>0.534676</td>\n",
       "      <td>0.103445</td>\n",
       "      <td>0.537709</td>\n",
       "      <td>0.163111</td>\n",
       "      <td>0.365190</td>\n",
       "      <td>0.470261</td>\n",
       "      <td>0.50063</td>\n",
       "      <td>0.052586</td>\n",
       "      <td>0.037161</td>\n",
       "      <td>0.963409</td>\n",
       "      <td>0.024613</td>\n",
       "      <td>0.465144</td>\n",
       "      <td>0.725007</td>\n",
       "      <td>0.535298</td>\n",
       "      <td>0.430795</td>\n",
       "      <td>0.677014</td>\n",
       "      <td>0.769150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.128858</td>\n",
       "      <td>0.326452</td>\n",
       "      <td>0.203097</td>\n",
       "      <td>0.305804</td>\n",
       "      <td>0.202616</td>\n",
       "      <td>0.492667</td>\n",
       "      <td>0.361448</td>\n",
       "      <td>0.481491</td>\n",
       "      <td>0.258058</td>\n",
       "      <td>0.34959</td>\n",
       "      <td>0.053004</td>\n",
       "      <td>0.065045</td>\n",
       "      <td>0.187173</td>\n",
       "      <td>0.070344</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>0.327305</td>\n",
       "      <td>0.226032</td>\n",
       "      <td>0.193838</td>\n",
       "      <td>0.393064</td>\n",
       "      <td>0.272840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.020740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.340608</td>\n",
       "      <td>0.338912</td>\n",
       "      <td>0.160961</td>\n",
       "      <td>0.512287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.603274</td>\n",
       "      <td>0.376569</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.065016</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.602510</td>\n",
       "      <td>0.980957</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age           job       marital     education       default  \\\n",
       "count  32950.000000  32950.000000  32950.000000  32950.000000  32950.000000   \n",
       "mean       0.284447      0.339288      0.391118      0.534676      0.103445   \n",
       "std        0.128858      0.326452      0.203097      0.305804      0.202616   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.185185      0.000000      0.333333      0.285714      0.000000   \n",
       "50%        0.259259      0.181818      0.333333      0.428571      0.000000   \n",
       "75%        0.370370      0.636364      0.666667      0.857143      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "            housing          loan       contact         month  day_of_week  \\\n",
       "count  32950.000000  32950.000000  32950.000000  32950.000000  32950.00000   \n",
       "mean       0.537709      0.163111      0.365190      0.470261      0.50063   \n",
       "std        0.492667      0.361448      0.481491      0.258058      0.34959   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.00000   \n",
       "25%        0.000000      0.000000      0.000000      0.333333      0.25000   \n",
       "50%        1.000000      0.000000      0.000000      0.444444      0.50000   \n",
       "75%        1.000000      0.000000      1.000000      0.666667      0.75000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.00000   \n",
       "\n",
       "           duration      campaign         pdays      previous      poutcome  \\\n",
       "count  32950.000000  32950.000000  32950.000000  32950.000000  32950.000000   \n",
       "mean       0.052586      0.037161      0.963409      0.024613      0.465144   \n",
       "std        0.053004      0.065045      0.187173      0.070344      0.181400   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.020740      0.000000      1.000000      0.000000      0.500000   \n",
       "50%        0.036600      0.023810      1.000000      0.000000      0.500000   \n",
       "75%        0.065016      0.047619      1.000000      0.000000      0.500000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       emp.var.rate  cons.price.idx  cons.conf.idx     euribor3m   nr.employed  \n",
       "count  32950.000000    32950.000000   32950.000000  32950.000000  32950.000000  \n",
       "mean       0.725007        0.535298       0.430795      0.677014      0.769150  \n",
       "std        0.327305        0.226032       0.193838      0.393064      0.272840  \n",
       "min        0.000000        0.000000       0.000000      0.000000      0.000000  \n",
       "25%        0.333333        0.340608       0.338912      0.160961      0.512287  \n",
       "50%        0.937500        0.603274       0.376569      0.957379      0.859735  \n",
       "75%        1.000000        0.698753       0.602510      0.980957      1.000000  \n",
       "max        1.000000        1.000000       1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "#KNN - As the KNN algorithm works well and gives good accuracy with most of the classification problems, it is used in this case.\n",
    "###################\n",
    "\n",
    "KNN_Model_Def = KNeighborsClassifier(n_neighbors=3) # no of k is taken 3 as above this the accuracy is decreased.\n",
    "KNN_Model_Fit = KNN_Model_Def.fit(X_train,y_train)\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_KNN = KNN_Model_Fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.66229667395\n",
      "Precision: 0.5174418604651163\n",
      "Recall: 0.2804621848739496\n",
      "F1-Score: 0.36376021798365127\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_KNN)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/X_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_KNN)}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_KNN)}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_KNN)}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# DT\n",
    "###################\n",
    "\n",
    "DT_Model_Def = DecisionTreeClassifier(random_state=123)\n",
    "DT_Model_Fit = DT_Model_Def.fit(X_train,y_train)\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_DT = DT_Model_Fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.80796309783928\n",
      "Precision: 0.5160256410256411\n",
      "Recall: 0.5073529411764706\n",
      "F1-Score: 0.5116525423728814\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_DT)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/X_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_DT)}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_DT)}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_DT)}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Random Forest -Now trying with an ensemble method to see if it increases the accuracy\n",
    "###################\n",
    "\n",
    "RF_Model_Def = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "RF_Model_Fit = RF_Model_Def.fit(X_train,y_train)\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_RF = RF_Model_Fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.85943190094683\n",
      "Precision: 0.6571879936808847\n",
      "Recall: 0.4369747899159664\n",
      "F1-Score: 0.5249211356466877\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_RF)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/X_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_RF)}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_RF)}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_RF)}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# SVM\n",
    "###################\n",
    "\n",
    "SVM_Model_Def = SVC(decision_function_shape='ovo',kernel='linear')\n",
    "SVM_Model_Fit = SVM_Model_Def.fit(X_train,y_train)\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_SVM = SVM_Model_Fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.45132313668365\n",
      "Precision: 0.6189111747851003\n",
      "Recall: 0.226890756302521\n",
      "F1-Score: 0.3320522674865488\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_SVM)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/X_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_SVM)}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_SVM)}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_SVM)}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Logistic Regression\n",
    "###################\n",
    "\n",
    "LR_Model_Def = LogisticRegression(solver='liblinear', max_iter=500)\n",
    "LR_Model_Fit = LR_Model_Def.fit(X_train,y_train) #Model with balanced data\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_LR = LR_Model_Fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.82301529497451\n",
      "Precision: 0.6877394636015326\n",
      "Recall: 0.37710084033613445\n",
      "F1-Score: 0.4871099050203528\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_LR)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/X_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_LR)}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_LR)}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_LR)}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36548\n",
       "1     4640\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above that the distribution of samples between the two class are not balanced. The samples for class 0 is significantly more than the samples for class 1. In such a case when there is imbalance in the class distribution, considering accuracy as the performance measure will not give a correct evaluation of the models.\n",
    "In such a case, F1 Score is additionaly considered to evaluate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>88.66</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>88.80</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>90.85</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>89.45</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>90.82</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  F1Score\n",
       "KNN                     88.66     0.36\n",
       "DecisionTree            88.80     0.51\n",
       "RandomForest            90.85     0.52\n",
       "SVM                     89.45     0.33\n",
       "Logistic Regression     90.82     0.48"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BasicModel_Score = pd.DataFrame({'Accuracy': [88.66, 88.80, 90.85, 89.45,90.82],\n",
    "'F1Score': [0.36, 0.51,0.52,0.33,0.48]} , index=['KNN', 'DecisionTree', 'RandomForest', 'SVM', 'Logistic Regression'])\n",
    "BasicModel_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the models built using KNN, Decision Tree, Random Forest, SVM, and Logistic Regression.\n",
    "There are three models with better accuracy which are Random Forest, SVM, and Logistic Regression.\n",
    "There are two models with better F1 Score which are Decision tree and Random Forest.\n",
    "But still the F1 score can be improved.\n",
    "To improve the performance of the models one approach can be to balance the data using under or over sampling techniques.\n",
    "There are many variations of SMOTE used along with other techniques. \n",
    "Here Iam using SMOTE + ENN algorithm which avoids sample overlapping and creates data with good seperation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "smENN = SMOTEENN(random_state=123)\n",
    "SMENN_X, SMENN_Y = smENN.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65293, 20) (65293,)\n"
     ]
    }
   ],
   "source": [
    "print(SMENN_X.shape, SMENN_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    35172\n",
       "0    30121\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMENN_Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the samples are almost balanced between the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train  (52234, 20)\n",
      "x_test  (13059, 20)\n",
      "y_train  (52234,)\n",
      "y_test  (13059,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train, y_test = train_test_split(SMENN_X, SMENN_Y, train_size = 0.8, random_state = 123)\n",
    "print(\"x_train \",x_train.shape)\n",
    "print(\"x_test \",x_test.shape)\n",
    "print(\"y_train \",y_train.shape)\n",
    "print(\"y_test \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Standardization - Input variable\n",
    "###################\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "Scaling = MinMaxScaler().fit(x_train)\n",
    "x_train_std = Scaling.transform(x_train) # This step standardizes the train input data\n",
    "x_test_std = Scaling.transform(x_test) # This step standardizes the test input data\n",
    "\n",
    "X_train = pd.DataFrame(x_train_std, columns = x_train.columns)\n",
    "X_test = pd.DataFrame(x_test_std, columns = x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "#KNN - As the KNN algorithm works well and gives good accuracy with most of the classification problems, it is used in this case.\n",
    "###################\n",
    "\n",
    "KNN_Model_Def = KNeighborsClassifier(n_neighbors=3) # no of k is taken 3 as above this the accuracy is decreased.\n",
    "KNN_Model_Fit = KNN_Model_Def.fit(X_train,y_train)\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_KNN = KNN_Model_Fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.97802281951145\n",
      "Precision: 0.9418907198612315\n",
      "Recall: 0.9267529512160433\n",
      "F1-Score: 0.934260520467417\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_KNN)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/X_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_KNN)}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_KNN)}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_KNN)}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# DT\n",
    "###################\n",
    "\n",
    "DT_Model_Def = DecisionTreeClassifier(random_state=123)\n",
    "DT_Model_Fit = DT_Model_Def.fit(X_train,y_train)\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_DT = DT_Model_Fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.4500344589938\n",
      "Precision: 0.9732899943470887\n",
      "Recall: 0.9795192717963306\n",
      "F1-Score: 0.9763946976678245\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_DT)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/X_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_DT)}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_DT)}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_DT)}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Random Forest -Now trying with an ensemble method to see if it increases the accuracy\n",
    "###################\n",
    "\n",
    "RF_Model_Def = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "RF_Model_Fit = RF_Model_Def.fit(X_train,y_train)\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_RF = RF_Model_Fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.08561145570106\n",
      "Precision: 0.9782762025673579\n",
      "Recall: 0.9863461811975537\n",
      "F1-Score: 0.9822946175637393\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_RF)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/X_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_RF)}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_RF)}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_RF)}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# SVM\n",
    "###################\n",
    "\n",
    "SVM_Model_Def = SVC(decision_function_shape='ovo',kernel='linear')\n",
    "SVM_Model_Fit = SVM_Model_Def.fit(X_train,y_train)\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_SVM = SVM_Model_Fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.10368328355923\n",
      "Precision: 0.9360635185959048\n",
      "Recall: 0.9557673161712417\n",
      "F1-Score: 0.9458128078817735\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_SVM)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/X_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_SVM)}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_SVM)}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_SVM)}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Logistic Regression\n",
    "###################\n",
    "\n",
    "LR_Model_Def = LogisticRegression(solver='liblinear', max_iter=500)\n",
    "LR_Model_Fit = LR_Model_Def.fit(X_train,y_train) #Model with balanced data\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_LR = LR_Model_Fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.90458687495214\n",
      "Precision: 0.939022672862977\n",
      "Recall: 0.9483714976532499\n",
      "F1-Score: 0.943673931502972\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_LR)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/X_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_LR)}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_LR)}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_LR)}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>92.97</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>97.45</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>98.08</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>94.10</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>93.90</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  F1Score\n",
       "KNN                     92.97     0.93\n",
       "DecisionTree            97.45     0.97\n",
       "RandomForest            98.08     0.98\n",
       "SVM                     94.10     0.94\n",
       "Logistic Regression     93.90     0.94"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BalancedModel_Score = pd.DataFrame({'Accuracy': [92.97, 97.45, 98.08, 94.10, 93.9],\n",
    "'F1Score': [0.93, 0.97,0.98,0.94,0.94]} , index=['KNN', 'DecisionTree', 'RandomForest', 'SVM', 'Logistic Regression'])\n",
    "BalancedModel_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Unbalanced Data</th>\n",
       "      <th>KNN</th>\n",
       "      <td>88.66</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>88.80</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>90.85</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>89.45</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>90.82</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Balanced Data</th>\n",
       "      <th>KNN</th>\n",
       "      <td>92.97</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>97.45</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>98.08</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>94.10</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>93.90</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Accuracy  F1Score\n",
       "Unbalanced Data KNN                     88.66     0.36\n",
       "                DecisionTree            88.80     0.51\n",
       "                RandomForest            90.85     0.52\n",
       "                SVM                     89.45     0.33\n",
       "                Logistic Regression     90.82     0.48\n",
       "Balanced Data   KNN                     92.97     0.93\n",
       "                DecisionTree            97.45     0.97\n",
       "                RandomForest            98.08     0.98\n",
       "                SVM                     94.10     0.94\n",
       "                Logistic Regression     93.90     0.94"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([BasicModel_Score, BalancedModel_Score], keys=['Unbalanced Data', 'Balanced Data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After balancing the data the performance of the models have improved which has increased both the accuracy and the F1 Score of the models, even the precision and Recall score of the balanced models have become good.\n",
    "\n",
    "The tree based models Decision tree and Random Forest has very good accuracy as the tree models are robust towards the class distribution and linearity of the data, so even when the data was imbalanced it gave a moderate F1 score. But after the data is balanced the performance has still improved and given good accuracy and F1 Score.\n",
    "\n",
    "The instance based models KNN and SVM though it gave good accuracy in the unbalanced data but the F1 score was poor due to the class imbalance as the model can predict the value of the majority class for all predictions and achieve a high classification accuracy but the predictions of the minority class will be poor, Which is given by the F1 Score 2*((precision*recall) /(precision+recall)), as F1 score conveys the balance between the precision and the recall.\n",
    "\n",
    "So, when the data was balanced this improved the F1 Score as the predictions of both the classes are balanced now.\n",
    "\n",
    "The logistic regression models whose performance depends on the linearity of the model, performed moderate with the imbalanced data as the accuracy was good and F1 Score was moderate. But with the balanced data the performance has improved with a good accuracy and good F1 score.\n",
    "\n",
    "As the Random forest model has both the highest accuracy and highest F1 Score it can be used for the new data predictions.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
